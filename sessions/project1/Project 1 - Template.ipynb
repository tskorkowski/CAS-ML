{"cells":[{"cell_type":"markdown","metadata":{"id":"a7Bf9ZaIwstM"},"source":["### Introduction to Machine Learning in Finance and Insurance (Spring 2024)\n","# Project 1: Credit Analytics"]},{"cell_type":"markdown","metadata":{"id":"EIIAiZoGCFr-"},"source":["### Team members: LastName1 FirstName1, LastName2 FirstName2, LastName3 FirstName3"]},{"cell_type":"code","execution_count":245,"metadata":{"id":"tBchH-QYCFr-"},"outputs":[],"source":["### Import all the Python libraries you are going to use\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from typing import Callable"]},{"cell_type":"code","execution_count":246,"metadata":{"id":"xy1f6bjaCFr_"},"outputs":[],"source":["### Fix random seed for reproducibility\n","np.random.seed(10)"]},{"cell_type":"markdown","metadata":{"id":"79GLxyheCFsA"},"source":["# Exercise 1. Dataset features generation."]},{"cell_type":"code","execution_count":247,"metadata":{"id":"myAkFsvViXUx"},"outputs":[],"source":["# Data set params\n","age_lower_bound = 18\n","age_upper_bound = 80.000001\n","\n","income_lower_bound = 1\n","income_upper_bound = 15.000001\n","\n","p_self_emplyed = .1\n","\n","# train set power\n","m = int(2e4)\n","# test set power\n","n = int(1e4)\n","\n","feature_headers = ['x_1', 'x_2', 'x_3']\n","\n","# Age ,income and employment data\n","data = pd.DataFrame((np.random.uniform(age_lower_bound,age_upper_bound, m+n),\n","                     np.random.uniform(income_lower_bound,income_upper_bound, m+n),\n","                     np.random.binomial(1, p_self_emplyed, size = m+n))).transpose()\n","data.columns=feature_headers"]},{"cell_type":"markdown","metadata":{"id":"4L0pOrESCFsA"},"source":["# Exercise 2. Dataset labels generation."]},{"cell_type":"code","execution_count":248,"metadata":{"id":"qrop5PjoCFsB"},"outputs":[],"source":["# Define logistic function\n","def logistic(z:float) -> float:\n","    return 1 / (1 + np.exp(-z))\n","\n","# Define p1 parameters and function\n","p1_intecept = -13.3\n","p1_coeff = np.array([0.33,-3.5,3])\n","\n","def p1(intecept: float, coeff: float, row:float) -> float:\n","    z = intecept + np.dot(coeff, row)\n","    return logistic(z)\n","\n","# Define p2 parameters and function\n","p2_intecept = -5\n","p2_coeff = np.array([10,-1.1,1])\n","age_lower_bound = 25\n","age_upper_bound = 75\n","\n","# define arbitrary indicator function\n","def indic(low_bound: float, up_bound: float) -> Callable[[float], int]:\n","    \"\"\" Indicator function generator with specified lower boundary\n","        and upper boundary\n","\n","    Args:\n","        low_bound (float): lower boundary for indicator function\n","        up_bound (float): upper boundary for indicator function\n","\n","    Returns:\n","        function: returning 1 below lower boundary, 1 above upper boundary\n","                  and 0 otherwise\n","    \"\"\"\n","    assert low_bound <= up_bound, 'lower boundary has to be less or equal to upper boundary'\n","    def inner_function(x):\n","        return 1 if x < low_bound else -1 if x > up_bound else 0\n","    return inner_function\n","\n","def p2(intecept: float, coeff: float, row:float)-> float:\n","    # define indicator function according to the requirement\n","    p2_indicator = indic(age_lower_bound, age_upper_bound)\n","    \n","    # transform 'x_1'\n","    row_trasformed = row.copy()\n","    row_trasformed.loc['x_1'] = p2_indicator(row_trasformed.loc['x_1'])\n","\n","    # apply scalar product to the transformation\n","    z = intecept + np.dot(coeff, row_trasformed)\n","    \n","    return logistic(z)"]},{"cell_type":"code","execution_count":249,"metadata":{},"outputs":[],"source":["df_prob = pd.DataFrame()\n","df_prob['p_1'] = data.apply(lambda row: p1(p1_intecept, p1_coeff, row), axis = 1)\n","df_prob['p_2'] = data.apply(lambda row: p2(p2_intecept, p2_coeff, row), axis = 1)"]},{"cell_type":"code","execution_count":264,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                y_1           y_2\n","count  30000.000000  30000.000000\n","mean       0.049333      0.030067\n","std        0.216567      0.170774\n","min        0.000000      0.000000\n","25%        0.000000      0.000000\n","50%        0.000000      0.000000\n","75%        0.000000      0.000000\n","max        1.000000      1.000000\n","y_1\n","0      28520\n","1       1480\n","Name: count, dtype: int64\n","y_2\n","0      29098\n","1        902\n","Name: count, dtype: int64\n"]}],"source":["df_y = pd.DataFrame()\n","for i, col in enumerate(df_prob.columns):\n","    df_y['y_'+str(i+1)] = np.random.binomial(1,df_prob[col])\n","\n","print(df_y.describe(),df_y.value_counts(['y_1']), df_y.value_counts(['y_2']), sep='\\n')"]},{"cell_type":"markdown","metadata":{"id":"ZZpEp3e-pklL"},"source":["# Exercise 3. Model implementations."]},{"cell_type":"markdown","metadata":{"id":"DL86ss7DCFsB"},"source":["### 3a) Logistic regression (LR)"]},{"cell_type":"code","execution_count":266,"metadata":{"id":"fkLKkb04CFsC"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression # logistic regression model\n","from sklearn.metrics import log_loss # cross-entropy\n","\n","# Implement and train a logistic regression model\n","# You can use LogisticRegression() from sklearn.linear_model (see the notebook \"Project 1 - Sandbox.ipynb\")\n","# For more information, see: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","\n","# Attention! Set the argument penalty=None to implement a logistic regression without regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmeXoFqdppk1"},"outputs":[],"source":["# Compute the cross-entropy loss on the training and test data."]},{"cell_type":"markdown","metadata":{"id":"2IO8tXdzZ1IB"},"source":["### 3b) Neural network (NN)"]},{"cell_type":"code","execution_count":270,"metadata":{"id":"wrE1FTViCFsC"},"outputs":[],"source":["import keras\n","# Implement and train a neural network model\n","# You can use Keras (see the notebook \"Project 1 - Credit risk - Sandbox\")\n","# For more information, see: https://keras.io/getting_started/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFSguoK1CFsC"},"outputs":[],"source":["# Compute the cross-entropy loss on the training and test data."]},{"cell_type":"markdown","metadata":{"id":"5QGt35lpCFsC"},"source":["### 3c) ROC curves and AUC scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBzTdew5j2h0"},"outputs":[],"source":["# Plot the ROC curves and compute the AUC scores\n","# You can use roc_auc_score and roc_curve from sklearn.metrics"]},{"cell_type":"markdown","metadata":{"id":"7ESezTJnIqp4"},"source":["# Exercise 4. Comparison of lending strategies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4Azky6yCFsD"},"outputs":[],"source":["# Implement a function to compute the Value at Risk (VaR) at level alpha on the vector x\n","\n","def var(x, alpha):\n","    # Write your code here and return your VaR(alpha) estimate\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bb0p5HSAIuBd"},"outputs":[],"source":["# Implement strategy (i), plot the P&L histogram and compute VaR(95%) of the losses\n","\n","# Implement strategy (ii), plot the P&L histogram and compute VaR(95%) of the losses\n","\n","# Implement strategy (iii), plot the P&L histogram and compute VaR(95%) of the losses"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
